{"ast":null,"code":"import React,{useEffect,useMemo,useRef}from'react';import'./Tile.css';function getTrackUnavailableMessage(kind,trackState){if(!trackState)return;switch(trackState.state){case'blocked':if(trackState.blocked.byPermissions){return\"\".concat(kind,\" permission denied\");}else if(trackState.blocked.byDeviceMissing){return\"\".concat(kind,\" device missing\");}return\"\".concat(kind,\" blocked\");case'off':if(trackState.off.byUser){return\"\".concat(kind,\" muted\");}else if(trackState.off.byBandwidth){return\"\".concat(kind,\" muted to save bandwidth\");}return\"\".concat(kind,\" off\");case'sendable':return\"\".concat(kind,\" not subscribed\");case'loading':return\"\".concat(kind,\" loading...\");case'interrupted':return\"\".concat(kind,\" interrupted\");case'playable':return null;}}/**\n * Props\n * - videoTrackState: DailyTrackState?\n * - audioTrackState: DailyTrackState?\n * - isLocalPerson: boolean\n * - isAudioOnly: boolean\n * - isLarge: boolean\n * - disableCornerMessage: boolean\n * - onClick: Function\n * -isScreenShare: boolean\n */export default function Tile(props){var videoEl=useRef(null);var audioEl=useRef(null);var videoTrack=useMemo(function(){return props.videoTrackState&&props.videoTrackState.state==='playable'&&(props.isLocalPerson||props.videoTrackState.subscribed===true)?props.videoTrackState.track:null;},[props.videoTrackState]);var audioTrack=useMemo(function(){if(!props.audioTrackState||!props.audioTrackState.track||props.audioTrackState.state!=='playable'||props.audioTrackState.subscribed===false){return null;}// if(props.disableCornerMessage) {console.log('Is a screen share');}\nif(props.isAudioOnly){props.audioTrackState.track.isFiltered=true;}else{props.audioTrackState.track.isFiltered=false;}if(props.isScreenShare){props.audioTrackState.track.isScreenShare=true;}else{props.audioTrackState.track.isScreenShare=false;}return props.audioTrackState.track;},[props.audioTrackState]);var videoUnavailableMessage=useMemo(function(){return getTrackUnavailableMessage('video',props.videoTrackState);},[props.videoTrackState]);var audioUnavailableMessage=useMemo(function(){return getTrackUnavailableMessage('audio',props.audioTrackState);},[props.audioTrackState]);/**\n   * When video track changes, update video srcObject\n   */useEffect(function(){videoEl.current&&(videoEl.current.srcObject=new MediaStream([videoTrack]));},[videoTrack]);/**\n   * When audio track changes, update audio srcObject\n   */useEffect(function(){if(audioEl.current){// TODO: PUT THIS BACK\n// //create audio stream\n// window.stream= window.stream || new MediaStream([audioTrack]);\n// //workaround for bug in Chrome, see: https://bit.ly/3ryn1fW\n//       window.mutedAudio = window.mutedAudio || new Audio(); \n//       window.mutedAudio.muted = true;\n//       if(!window.mutedAudio.srcObject) {window.mutedAudio.srcObject = window.stream;}\n//       window.mutedAudio.paused && window.mutedAudio.play(); \n// //create Audio Context and destination\n// window.audioCtx = new (window.AudioContext || window.webkitAudioContext)();\n// let audioSourceNode = window.audioCtx.createMediaStreamSource(window.stream);\n// let destination = window.audioCtx.createMediaStreamDestination();\n// //gain Node\n// let gainNode = window.audioCtx.createGain();\n// //panner Node\n// var panNode = window.audioCtx.createStereoPanner();\n// //splitter\n// if(audioTrack.isFiltered) {\n//   console.log('**FILTERING LIVE TRACK**')\n//         //adjust nodes\n//         gainNode.gain.value=1;\n//         panNode.pan.value=1;      \n//         //Pipe source through nodes to destination\n//       audioSourceNode.connect(gainNode).connect(panNode).connect(destination);\n// } \n// else if(audioTrack.isScreenShare) {\n//   //for everyone, just piping the received audio (which was the left channel of the original video) straight through\n//   console.log('***GETTING SCREENSHARE AUDIO')\n//   audioSourceNode.connect(destination);\n//   ///OLD CODE FOR IF IT RECEIVED STEREO AUDIO:\n//   // const splitterNode = new ChannelSplitterNode(audioCtx, { numberOfOutputs: 2 });\n//   // const splitterNodeLL = new ChannelSplitterNode(audioCtx, { numberOfOutputs: 2 });\n//   // const mergerNode = new ChannelMergerNode(audioCtx, { numberOfInputs: 2 });\n//   // const mergerNodeR = new ChannelMergerNode(audioCtx, { numberOfInputs: 2 });\n//   // const volumeNodeL = new GainNode(audioCtx);\n//   // const volumeNodeR = new GainNode(audioCtx);\n//   // if(window.myRole.includes('Actor')) {   //For actors, mix left channel into both sides and keep right channel\n//   //   console.log('**FILTERING: SCREENSHARE AUDIO FOR ACTOR**')\n//   //   // //split audio source into 2 channels: 0 (left), and 1(right)\n//   //   // audioSourceNode.connect(splitterNode)  \n//   //   // splitterNode.connect(splitterNodeLL,0); //split left channel again\n//   //   // //mix the left and right into the new right channel\n//   //   // splitterNodeLL.connect(mergerNodeR, 0, 1); // Merge right of the left channel into right side\n//   //   // splitterNode.connect(mergerNodeR, 0, 1); // Merge right channel into right side\n//   //   // //merge far left and new right\n//   //   // splitterNodeLL.connect(mergerNode, 0, 0);\n//   //   // mergerNodeR.connect(mergerNode, 0, 1);\n//   //   audioSourceNode.connect(mergerNode,0,0);\n//   //   audioSourceNode.connect(mergerNode,0,1);\n//   // } else {        //For everyone else , mix left channel into both sides and mute right channel\n//   //   console.log('**FILTERING: SCREENSHARE AUDIO FOR OBSERVER**')\n//   //   //split audio source into 2 channels: 0 (left), and 1(right)\n//   //   audioSourceNode.connect(splitterNode)\n//   //   //adjust channels separately\n//   //   splitterNode.connect(volumeNodeL, 0); // connect Left channel to its volume node\n//   //   splitterNode.connect(volumeNodeR, 1); // connect Right channel to its volume node\n//   //   volumeNodeL.gain.value = 1; //set Left volume\n//   //   volumeNodeR.gain.value = 1; //set Right volume\n//   //   //merge the channels\n//   //   volumeNodeL.connect(mergerNode, 0, 0); // Merge left channel\n//   //   volumeNodeR.connect(mergerNode, 0, 1); // Merge right channel\n//   //   // volumeNodeR.connect(mergerNode, 0, 0);\n//   // }\n//   //   //finally, connect to destination\n//   //   mergerNode.connect(destination);\n// }\n// else {      //For normal live tracks\n//   console.log('***NOT FILTERING: LIVE TRACK***')\n//    //Pipe source *straight* to destination\n//   audioSourceNode.connect(gainNode).connect(destination);\n// }\n//     //Attach to the audio element\n//     audioEl.current.srcObject = destination.stream;\n//END TODO\n// how to do this without audiocontext:\naudioEl.current.srcObject=new MediaStream([audioTrack]);// for debugging\n// window.destination=destination; \n// window.audioTrack=audioTrack;\n// window.audioEl = audioEl;\n}},[audioTrack,window.sessionState]);function getVideoComponent(){return videoTrack&&/*#__PURE__*/React.createElement(\"video\",{autoPlay:true,muted:true,playsInline:true,ref:videoEl});}function getAudioComponent(){return!props.isLocalPerson&&audioTrack&&/*#__PURE__*/React.createElement(\"audio\",{autoPlay:true,playsInline:true,ref:audioEl},\" \");}function getOverlayComponent(){// Show overlay when video is unavailable. Audio may be unavailable too.\nreturn videoTrack&&videoUnavailableMessage&&/*#__PURE__*/React.createElement(\"p\",{className:\"overlay\"},videoUnavailableMessage);}function getCornerMessageComponent(){// Show corner message when only audio is unavailable.\nreturn!props.disableCornerMessage&&audioUnavailableMessage&&!videoUnavailableMessage&&/*#__PURE__*/React.createElement(\"p\",{className:\"corner\"},audioUnavailableMessage);}function getClassNames(){var classNames='tile';classNames+=props.isLarge?' large':' small';props.isLocalPerson&&(classNames+=' local');return classNames;}return/*#__PURE__*/ (///TODO change to block : none\nReact.createElement(\"div\",{className:getClassNames(),onClick:props.onClick,style:{display:videoTrack?\"block\":\"none\"}},/*#__PURE__*/React.createElement(\"div\",{className:\"background\"}),getOverlayComponent(),getVideoComponent(),videoTrack&&getCornerMessageComponent(),getAudioComponent()));}","map":{"version":3,"sources":["/Users/arlosb/Documents/GitHub/new react app/test1/src/components/Tile/Tile.js"],"names":["React","useEffect","useMemo","useRef","getTrackUnavailableMessage","kind","trackState","state","blocked","byPermissions","byDeviceMissing","off","byUser","byBandwidth","Tile","props","videoEl","audioEl","videoTrack","videoTrackState","isLocalPerson","subscribed","track","audioTrack","audioTrackState","isAudioOnly","isFiltered","isScreenShare","videoUnavailableMessage","audioUnavailableMessage","current","srcObject","MediaStream","window","sessionState","getVideoComponent","getAudioComponent","getOverlayComponent","getCornerMessageComponent","disableCornerMessage","getClassNames","classNames","isLarge","onClick","display"],"mappings":"AAAA,MAAOA,CAAAA,KAAP,EAAgBC,SAAhB,CAA2BC,OAA3B,CAAoCC,MAApC,KAAkD,OAAlD,CACA,MAAO,YAAP,CAEA,QAASC,CAAAA,0BAAT,CAAoCC,IAApC,CAA0CC,UAA1C,CAAsD,CACpD,GAAI,CAACA,UAAL,CAAiB,OACjB,OAAQA,UAAU,CAACC,KAAnB,EACE,IAAK,SAAL,CACE,GAAID,UAAU,CAACE,OAAX,CAAmBC,aAAvB,CAAsC,CACpC,gBAAUJ,IAAV,uBACD,CAFD,IAEO,IAAIC,UAAU,CAACE,OAAX,CAAmBE,eAAvB,CAAwC,CAC7C,gBAAUL,IAAV,oBACD,CACD,gBAAUA,IAAV,aACF,IAAK,KAAL,CACE,GAAIC,UAAU,CAACK,GAAX,CAAeC,MAAnB,CAA2B,CACzB,gBAAUP,IAAV,WACD,CAFD,IAEO,IAAIC,UAAU,CAACK,GAAX,CAAeE,WAAnB,CAAgC,CACrC,gBAAUR,IAAV,6BACD,CACD,gBAAUA,IAAV,SACF,IAAK,UAAL,CACE,gBAAUA,IAAV,oBACF,IAAK,SAAL,CACE,gBAAUA,IAAV,gBACF,IAAK,aAAL,CACE,gBAAUA,IAAV,iBACF,IAAK,UAAL,CACE,MAAO,KAAP,CAtBJ,CAwBD,CAED;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA,GACA,cAAe,SAASS,CAAAA,IAAT,CAAcC,KAAd,CAAqB,CAClC,GAAMC,CAAAA,OAAO,CAAGb,MAAM,CAAC,IAAD,CAAtB,CACA,GAAMc,CAAAA,OAAO,CAAGd,MAAM,CAAC,IAAD,CAAtB,CAEA,GAAMe,CAAAA,UAAU,CAAGhB,OAAO,CAAC,UAAM,CAC/B,MAAOa,CAAAA,KAAK,CAACI,eAAN,EAAyBJ,KAAK,CAACI,eAAN,CAAsBZ,KAAtB,GAAgC,UAAzD,GAAwEQ,KAAK,CAACK,aAAN,EAAuBL,KAAK,CAACI,eAAN,CAAsBE,UAAtB,GAAqC,IAApI,EACHN,KAAK,CAACI,eAAN,CAAsBG,KADnB,CAEH,IAFJ,CAGD,CAJyB,CAIvB,CAACP,KAAK,CAACI,eAAP,CAJuB,CAA1B,CAMA,GAAMI,CAAAA,UAAU,CAAGrB,OAAO,CAAC,UAAM,CAE/B,GAAI,CAACa,KAAK,CAACS,eAAP,EAA0B,CAACT,KAAK,CAACS,eAAN,CAAsBF,KAAjD,EAA0DP,KAAK,CAACS,eAAN,CAAsBjB,KAAtB,GAAgC,UAA1F,EAAwGQ,KAAK,CAACS,eAAN,CAAsBH,UAAtB,GAAqC,KAAjJ,CACI,CAAC,MAAO,KAAP,CAAa,CAClB;AACA,GAAIN,KAAK,CAACU,WAAV,CAAuB,CACrBV,KAAK,CAACS,eAAN,CAAsBF,KAAtB,CAA4BI,UAA5B,CAAuC,IAAvC,CACD,CAFD,IAEO,CAACX,KAAK,CAACS,eAAN,CAAsBF,KAAtB,CAA4BI,UAA5B,CAAuC,KAAvC,CAA8C,CACtD,GAAIX,KAAK,CAACY,aAAV,CAAyB,CACvBZ,KAAK,CAACS,eAAN,CAAsBF,KAAtB,CAA4BK,aAA5B,CAA0C,IAA1C,CACD,CAFD,IAEO,CAACZ,KAAK,CAACS,eAAN,CAAsBF,KAAtB,CAA4BK,aAA5B,CAA0C,KAA1C,CAAiD,CACzD,MAAOZ,CAAAA,KAAK,CAACS,eAAN,CAAsBF,KAA7B,CACD,CAZyB,CAYvB,CAACP,KAAK,CAACS,eAAP,CAZuB,CAA1B,CAcA,GAAMI,CAAAA,uBAAuB,CAAG1B,OAAO,CAAC,UAAM,CAC5C,MAAOE,CAAAA,0BAA0B,CAAC,OAAD,CAAUW,KAAK,CAACI,eAAhB,CAAjC,CACD,CAFsC,CAEpC,CAACJ,KAAK,CAACI,eAAP,CAFoC,CAAvC,CAIA,GAAMU,CAAAA,uBAAuB,CAAG3B,OAAO,CAAC,UAAM,CAC5C,MAAOE,CAAAA,0BAA0B,CAAC,OAAD,CAAUW,KAAK,CAACS,eAAhB,CAAjC,CACD,CAFsC,CAEpC,CAACT,KAAK,CAACS,eAAP,CAFoC,CAAvC,CAIA;AACF;AACA,KACEvB,SAAS,CAAC,UAAM,CACde,OAAO,CAACc,OAAR,GACGd,OAAO,CAACc,OAAR,CAAgBC,SAAhB,CAA4B,GAAIC,CAAAA,WAAJ,CAAgB,CAACd,UAAD,CAAhB,CAD/B,EAED,CAHQ,CAGN,CAACA,UAAD,CAHM,CAAT,CAKA;AACF;AACA,KACEjB,SAAS,CAAC,UAAM,CACd,GAAGgB,OAAO,CAACa,OAAX,CAAoB,CAIhB;AAGF;AACA;AAEA;AACA;AACA;AACA;AACA;AAEA;AACA;AACA;AACA;AAEA;AACA;AACA;AACA;AACA;AAQA;AACA;AACA;AACA;AACA;AACA;AACA;AAEA;AACA;AAEA;AACA;AACA;AAIA;AAEA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AAGA;AACA;AACA;AAEA;AACA;AACA;AAEA;AACA;AACA;AAEA;AACA;AAIA;AACA;AAEA;AACA;AAGA;AACA;AACA;AACA;AACA;AAEA;AACA;AACA;AACA;AACA;AAEA;AACA;AAEA;AACA;AACA;AACA;AAGA;AAIA;AAEA;AACA;AAEY;AAGX;AACCb,OAAO,CAACa,OAAR,CAAgBC,SAAhB,CAA4B,GAAIC,CAAAA,WAAJ,CAAgB,CAACT,UAAD,CAAhB,CAA5B,CAMF;AACA;AACA;AACA;AAEC,CAEJ,CAtIQ,CAsIN,CAACA,UAAD,CAAYU,MAAM,CAACC,YAAnB,CAtIM,CAAT,CAwIA,QAASC,CAAAA,iBAAT,EAA6B,CAC3B,MAAOjB,CAAAA,UAAU,eAAI,6BAAO,QAAQ,KAAf,CAAgB,KAAK,KAArB,CAAsB,WAAW,KAAjC,CAAkC,GAAG,CAAEF,OAAvC,EAArB,CAGD,CAED,QAASoB,CAAAA,iBAAT,EAA6B,CAC3B,MACE,CAACrB,KAAK,CAACK,aAAP,EACAG,UADA,eACc,6BAAO,QAAQ,KAAf,CAAgB,WAAW,KAA3B,CAA4B,GAAG,CAAEN,OAAjC,MAFhB,CAID,CAED,QAASoB,CAAAA,mBAAT,EAA+B,CAC7B;AACA,MAAOnB,CAAAA,UAAU,EACfU,uBAAuB,eACrB,yBAAG,SAAS,CAAC,SAAb,EACGA,uBADH,CAFJ,CAaD,CAED,QAASU,CAAAA,yBAAT,EAAqC,CACnC;AACA,MACE,CAACvB,KAAK,CAACwB,oBAAP,EACAV,uBADA,EAEA,CAACD,uBAFD,eAGE,yBAAG,SAAS,CAAC,QAAb,EAAuBC,uBAAvB,CAJJ,CAOD,CAED,QAASW,CAAAA,aAAT,EAAyB,CACvB,GAAIC,CAAAA,UAAU,CAAG,MAAjB,CACAA,UAAU,EAAI1B,KAAK,CAAC2B,OAAN,CAAgB,QAAhB,CAA2B,QAAzC,CACA3B,KAAK,CAACK,aAAN,GAAwBqB,UAAU,EAAI,QAAtC,EACA,MAAOA,CAAAA,UAAP,CACD,CAED,oBACE;AACA,2BAAK,SAAS,CAAED,aAAa,EAA7B,CAAiC,OAAO,CAAEzB,KAAK,CAAC4B,OAAhD,CAAyD,KAAK,CAAE,CAACC,OAAO,CAAE1B,UAAU,CAAG,OAAH,CAAa,MAAjC,CAAhE,eACE,2BAAK,SAAS,CAAC,YAAf,EADF,CAEGmB,mBAAmB,EAFtB,CAGGF,iBAAiB,EAHpB,CAIGjB,UAAU,EAAIoB,yBAAyB,EAJ1C,CAKGF,iBAAiB,EALpB,CAFF,EAUD","sourcesContent":["import React, { useEffect, useMemo, useRef } from 'react';\nimport './Tile.css';\n\nfunction getTrackUnavailableMessage(kind, trackState) {\n  if (!trackState) return;\n  switch (trackState.state) {\n    case 'blocked':\n      if (trackState.blocked.byPermissions) {\n        return `${kind} permission denied`;\n      } else if (trackState.blocked.byDeviceMissing) {\n        return `${kind} device missing`;\n      }\n      return `${kind} blocked`;\n    case 'off':\n      if (trackState.off.byUser) {\n        return `${kind} muted`;\n      } else if (trackState.off.byBandwidth) {\n        return `${kind} muted to save bandwidth`;\n      }\n      return `${kind} off`;\n    case 'sendable':\n      return `${kind} not subscribed`;\n    case 'loading':\n      return `${kind} loading...`;\n    case 'interrupted':\n      return `${kind} interrupted`;\n    case 'playable':\n      return null;\n  }\n}\n\n/**\n * Props\n * - videoTrackState: DailyTrackState?\n * - audioTrackState: DailyTrackState?\n * - isLocalPerson: boolean\n * - isAudioOnly: boolean\n * - isLarge: boolean\n * - disableCornerMessage: boolean\n * - onClick: Function\n * -isScreenShare: boolean\n */\nexport default function Tile(props) {\n  const videoEl = useRef(null);\n  const audioEl = useRef(null);\n\n  const videoTrack = useMemo(() => {\n    return props.videoTrackState && props.videoTrackState.state === 'playable' && (props.isLocalPerson || props.videoTrackState.subscribed === true)\n      ? props.videoTrackState.track\n      : null;\n  }, [props.videoTrackState]);\n\n  const audioTrack = useMemo(() => {\n\n    if (!props.audioTrackState || !props.audioTrackState.track || props.audioTrackState.state !== 'playable' || props.audioTrackState.subscribed === false) \n        {return null;}\n    // if(props.disableCornerMessage) {console.log('Is a screen share');}\n    if (props.isAudioOnly) {\n      props.audioTrackState.track.isFiltered=true;\n    } else {props.audioTrackState.track.isFiltered=false;}\n    if (props.isScreenShare) {\n      props.audioTrackState.track.isScreenShare=true;\n    } else {props.audioTrackState.track.isScreenShare=false;}\n    return props.audioTrackState.track\n  }, [props.audioTrackState]);\n\n  const videoUnavailableMessage = useMemo(() => {\n    return getTrackUnavailableMessage('video', props.videoTrackState);\n  }, [props.videoTrackState]);\n\n  const audioUnavailableMessage = useMemo(() => {\n    return getTrackUnavailableMessage('audio', props.audioTrackState);\n  }, [props.audioTrackState]);\n\n  /**\n   * When video track changes, update video srcObject\n   */\n  useEffect(() => {\n    videoEl.current &&\n      (videoEl.current.srcObject = new MediaStream([videoTrack]));\n  }, [videoTrack]);\n\n  /**\n   * When audio track changes, update audio srcObject\n   */\n  useEffect(() => {\n    if(audioEl.current) {\n\n\n\n        // TODO: PUT THIS BACK\n\n\n      // //create audio stream\n      // window.stream= window.stream || new MediaStream([audioTrack]);\n\n      // //workaround for bug in Chrome, see: https://bit.ly/3ryn1fW\n      //       window.mutedAudio = window.mutedAudio || new Audio(); \n      //       window.mutedAudio.muted = true;\n      //       if(!window.mutedAudio.srcObject) {window.mutedAudio.srcObject = window.stream;}\n      //       window.mutedAudio.paused && window.mutedAudio.play(); \n\n      // //create Audio Context and destination\n      // window.audioCtx = new (window.AudioContext || window.webkitAudioContext)();\n      // let audioSourceNode = window.audioCtx.createMediaStreamSource(window.stream);\n      // let destination = window.audioCtx.createMediaStreamDestination();\n\n      // //gain Node\n      // let gainNode = window.audioCtx.createGain();\n      // //panner Node\n      // var panNode = window.audioCtx.createStereoPanner();\n      // //splitter\n      \n\n\n\n\n\n      \n      // if(audioTrack.isFiltered) {\n      //   console.log('**FILTERING LIVE TRACK**')\n      //         //adjust nodes\n      //         gainNode.gain.value=1;\n      //         panNode.pan.value=1;      \n      //         //Pipe source through nodes to destination\n      //       audioSourceNode.connect(gainNode).connect(panNode).connect(destination);\n        \n      // } \n      // else if(audioTrack.isScreenShare) {\n\n      //   //for everyone, just piping the received audio (which was the left channel of the original video) straight through\n      //   console.log('***GETTING SCREENSHARE AUDIO')\n      //   audioSourceNode.connect(destination);\n\n\n\n      //   ///OLD CODE FOR IF IT RECEIVED STEREO AUDIO:\n        \n      //   // const splitterNode = new ChannelSplitterNode(audioCtx, { numberOfOutputs: 2 });\n      //   // const splitterNodeLL = new ChannelSplitterNode(audioCtx, { numberOfOutputs: 2 });\n      //   // const mergerNode = new ChannelMergerNode(audioCtx, { numberOfInputs: 2 });\n      //   // const mergerNodeR = new ChannelMergerNode(audioCtx, { numberOfInputs: 2 });\n      //   // const volumeNodeL = new GainNode(audioCtx);\n      //   // const volumeNodeR = new GainNode(audioCtx);\n      //   // if(window.myRole.includes('Actor')) {   //For actors, mix left channel into both sides and keep right channel\n      //   //   console.log('**FILTERING: SCREENSHARE AUDIO FOR ACTOR**')\n\n\n      //   //   // //split audio source into 2 channels: 0 (left), and 1(right)\n      //   //   // audioSourceNode.connect(splitterNode)  \n      //   //   // splitterNode.connect(splitterNodeLL,0); //split left channel again\n\n      //   //   // //mix the left and right into the new right channel\n      //   //   // splitterNodeLL.connect(mergerNodeR, 0, 1); // Merge right of the left channel into right side\n      //   //   // splitterNode.connect(mergerNodeR, 0, 1); // Merge right channel into right side\n\n      //   //   // //merge far left and new right\n      //   //   // splitterNodeLL.connect(mergerNode, 0, 0);\n      //   //   // mergerNodeR.connect(mergerNode, 0, 1);\n\n      //   //   audioSourceNode.connect(mergerNode,0,0);\n      //   //   audioSourceNode.connect(mergerNode,0,1);\n\n          \n\n      //   // } else {        //For everyone else , mix left channel into both sides and mute right channel\n      //   //   console.log('**FILTERING: SCREENSHARE AUDIO FOR OBSERVER**')\n\n      //   //   //split audio source into 2 channels: 0 (left), and 1(right)\n      //   //   audioSourceNode.connect(splitterNode)\n\n\n      //   //   //adjust channels separately\n      //   //   splitterNode.connect(volumeNodeL, 0); // connect Left channel to its volume node\n      //   //   splitterNode.connect(volumeNodeR, 1); // connect Right channel to its volume node\n      //   //   volumeNodeL.gain.value = 1; //set Left volume\n      //   //   volumeNodeR.gain.value = 1; //set Right volume\n\n      //   //   //merge the channels\n      //   //   volumeNodeL.connect(mergerNode, 0, 0); // Merge left channel\n      //   //   volumeNodeR.connect(mergerNode, 0, 1); // Merge right channel\n      //   //   // volumeNodeR.connect(mergerNode, 0, 0);\n      //   // }\n\n      //   //   //finally, connect to destination\n      //   //   mergerNode.connect(destination);\n\n      // }\n      // else {      //For normal live tracks\n      //   console.log('***NOT FILTERING: LIVE TRACK***')\n      //    //Pipe source *straight* to destination\n\n\n      //   audioSourceNode.connect(gainNode).connect(destination);\n\n     \n\n      // }\n\n      //     //Attach to the audio element\n      //     audioEl.current.srcObject = destination.stream;\n\n                  //END TODO\n\n\n       // how to do this without audiocontext:\n        audioEl.current.srcObject = new MediaStream([audioTrack]);\n\n     \n\n  \n\n      // for debugging\n      // window.destination=destination; \n      // window.audioTrack=audioTrack;\n      // window.audioEl = audioEl;\n\n      }\n      \n  }, [audioTrack,window.sessionState]);\n\n  function getVideoComponent() {\n    return videoTrack && <video autoPlay muted playsInline ref={videoEl} />;\n\n    \n  }\n\n  function getAudioComponent() {\n    return (\n      !props.isLocalPerson &&\n      audioTrack && <audio autoPlay playsInline ref={audioEl} > </audio>\n    );\n  }\n\n  function getOverlayComponent() {\n    // Show overlay when video is unavailable. Audio may be unavailable too.\n    return videoTrack && (\n      videoUnavailableMessage && (\n        <p className=\"overlay\">\n          {videoUnavailableMessage}\n          {/* {audioUnavailableMessage && (\n            <>\n              <br />\n              {audioUnavailableMessage}\n            </>\n          )} */}\n        </p>\n      )\n    );\n  }\n\n  function getCornerMessageComponent() {\n    // Show corner message when only audio is unavailable.\n    return (\n      !props.disableCornerMessage &&\n      audioUnavailableMessage &&\n      !videoUnavailableMessage && (\n        <p className=\"corner\">{audioUnavailableMessage}</p>\n      )\n    );\n  }\n\n  function getClassNames() {\n    let classNames = 'tile';\n    classNames += props.isLarge ? ' large' : ' small';\n    props.isLocalPerson && (classNames += ' local');\n    return classNames;\n  }\n\n  return (\n    ///TODO change to block : none\n    <div className={getClassNames()} onClick={props.onClick} style={{display: videoTrack ? \"block\" : \"none\"}}  >  \n      <div className=\"background\"/> \n      {getOverlayComponent()}\n      {getVideoComponent()}\n      {videoTrack && getCornerMessageComponent()}\n      {getAudioComponent()}\n    </div>\n  );\n}\n"]},"metadata":{},"sourceType":"module"}