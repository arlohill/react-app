{"ast":null,"code":"var _jsxFileName = \"/Users/arlosb/Documents/GitHub/new react app/test1/src/components/Tile/Tile.js\";\nimport React, { useEffect, useMemo, useRef, useState } from 'react';\nimport './Tile.css';\n\nfunction useForceUpdate() {\n  const [value, setValue] = useState(0); // integer state\n\n  return () => setValue(value => value + 1); // update the state to force render\n}\n\nfunction getTrackUnavailableMessage(kind, trackState) {\n  if (!trackState) return;\n\n  switch (trackState.state) {\n    case 'blocked':\n      if (trackState.blocked.byPermissions) {\n        return `${kind} permission denied`;\n      } else if (trackState.blocked.byDeviceMissing) {\n        return `${kind} device missing`;\n      }\n\n      return `${kind} blocked`;\n\n    case 'off':\n      if (trackState.off.byUser) {\n        return `${kind} muted`;\n      } else if (trackState.off.byBandwidth) {\n        return `${kind} muted to save bandwidth`;\n      }\n\n      return `${kind} off`;\n\n    case 'sendable':\n      return `${kind} not subscribed`;\n\n    case 'loading':\n      return `${kind} loading...`;\n\n    case 'interrupted':\n      return `${kind} interrupted`;\n\n    case 'playable':\n      return null;\n  }\n}\n/**\n * Props\n * - videoTrackState: DailyTrackState?\n * - audioTrackState: DailyTrackState?\n * - isLocalPerson: boolean\n * - isAudioOnly: boolean\n * - isLarge: boolean\n * - disableCornerMessage: boolean\n * - onClick: Function\n * -isScreenShare: boolean\n */\n\n\nexport default function Tile(props) {\n  const videoEl = useRef(null);\n  const audioEl = useRef(null);\n\n  window.updateTile = () => {\n    useForceUpdate();\n  };\n\n  const videoTrack = useMemo(() => {\n    return props.videoTrackState && props.videoTrackState.state === 'playable' && (props.isLocalPerson || props.videoTrackState.subscribed === true) ? props.videoTrackState.track : null;\n  }, [props.videoTrackState]);\n  const audioTrack = useMemo(() => {\n    if (!props.audioTrackState || !props.audioTrackState.track || props.audioTrackState.state !== 'playable' || props.audioTrackState.subscribed === false) {\n      return null;\n    } // if(props.disableCornerMessage) {console.log('Is a screen share');}\n\n\n    if (props.isAudioOnly) {\n      props.audioTrackState.track.isFiltered = true;\n    } else {\n      props.audioTrackState.track.isFiltered = false;\n    }\n\n    if (props.isScreenShare) {\n      props.audioTrackState.track.isScreenShare = true;\n    } else {\n      props.audioTrackState.track.isScreenShare = false;\n    }\n\n    return props.audioTrackState.track;\n  }, [props.audioTrackState]);\n  const videoUnavailableMessage = useMemo(() => {\n    return getTrackUnavailableMessage('video', props.videoTrackState);\n  }, [props.videoTrackState]);\n  const audioUnavailableMessage = useMemo(() => {\n    return getTrackUnavailableMessage('audio', props.audioTrackState);\n  }, [props.audioTrackState]);\n  /**\n   * When video track changes, update video srcObject\n   */\n\n  useEffect(() => {\n    videoEl.current && (videoEl.current.srcObject = new MediaStream([videoTrack]));\n  }, [videoTrack]);\n  /**\n   * When audio track changes, update audio srcObject\n   */\n\n  useEffect(() => {\n    if (audioEl.current) {\n      // TODO: PUT THIS BACK\n      // //create audio stream\n      // window.stream= window.stream || new MediaStream([audioTrack]);\n      // //workaround for bug in Chrome, see: https://bit.ly/3ryn1fW\n      //       window.mutedAudio = window.mutedAudio || new Audio(); \n      //       window.mutedAudio.muted = true;\n      //       if(!window.mutedAudio.srcObject) {window.mutedAudio.srcObject = window.stream;}\n      //       window.mutedAudio.paused && window.mutedAudio.play(); \n      // //create Audio Context and destination\n      // window.audioCtx = new (window.AudioContext || window.webkitAudioContext)();\n      // let audioSourceNode = window.audioCtx.createMediaStreamSource(window.stream);\n      // let destination = window.audioCtx.createMediaStreamDestination();\n      // //gain Node\n      // let gainNode = window.audioCtx.createGain();\n      // //panner Node\n      // var panNode = window.audioCtx.createStereoPanner();\n      // //splitter\n      // if(audioTrack.isFiltered) {\n      //   console.log('**FILTERING LIVE TRACK**')\n      //         //adjust nodes\n      //         gainNode.gain.value=1;\n      //         panNode.pan.value=1;      \n      //         //Pipe source through nodes to destination\n      //       audioSourceNode.connect(gainNode).connect(panNode).connect(destination);\n      // } \n      // else if(audioTrack.isScreenShare) {\n      //   //for everyone, just piping the received audio (which was the left channel of the original video) straight through\n      //   console.log('***GETTING SCREENSHARE AUDIO')\n      //   audioSourceNode.connect(destination);\n      //   ///OLD CODE FOR IF IT RECEIVED STEREO AUDIO:\n      //   // const splitterNode = new ChannelSplitterNode(audioCtx, { numberOfOutputs: 2 });\n      //   // const splitterNodeLL = new ChannelSplitterNode(audioCtx, { numberOfOutputs: 2 });\n      //   // const mergerNode = new ChannelMergerNode(audioCtx, { numberOfInputs: 2 });\n      //   // const mergerNodeR = new ChannelMergerNode(audioCtx, { numberOfInputs: 2 });\n      //   // const volumeNodeL = new GainNode(audioCtx);\n      //   // const volumeNodeR = new GainNode(audioCtx);\n      //   // if(window.myRole.includes('Actor')) {   //For actors, mix left channel into both sides and keep right channel\n      //   //   console.log('**FILTERING: SCREENSHARE AUDIO FOR ACTOR**')\n      //   //   // //split audio source into 2 channels: 0 (left), and 1(right)\n      //   //   // audioSourceNode.connect(splitterNode)  \n      //   //   // splitterNode.connect(splitterNodeLL,0); //split left channel again\n      //   //   // //mix the left and right into the new right channel\n      //   //   // splitterNodeLL.connect(mergerNodeR, 0, 1); // Merge right of the left channel into right side\n      //   //   // splitterNode.connect(mergerNodeR, 0, 1); // Merge right channel into right side\n      //   //   // //merge far left and new right\n      //   //   // splitterNodeLL.connect(mergerNode, 0, 0);\n      //   //   // mergerNodeR.connect(mergerNode, 0, 1);\n      //   //   audioSourceNode.connect(mergerNode,0,0);\n      //   //   audioSourceNode.connect(mergerNode,0,1);\n      //   // } else {        //For everyone else , mix left channel into both sides and mute right channel\n      //   //   console.log('**FILTERING: SCREENSHARE AUDIO FOR OBSERVER**')\n      //   //   //split audio source into 2 channels: 0 (left), and 1(right)\n      //   //   audioSourceNode.connect(splitterNode)\n      //   //   //adjust channels separately\n      //   //   splitterNode.connect(volumeNodeL, 0); // connect Left channel to its volume node\n      //   //   splitterNode.connect(volumeNodeR, 1); // connect Right channel to its volume node\n      //   //   volumeNodeL.gain.value = 1; //set Left volume\n      //   //   volumeNodeR.gain.value = 1; //set Right volume\n      //   //   //merge the channels\n      //   //   volumeNodeL.connect(mergerNode, 0, 0); // Merge left channel\n      //   //   volumeNodeR.connect(mergerNode, 0, 1); // Merge right channel\n      //   //   // volumeNodeR.connect(mergerNode, 0, 0);\n      //   // }\n      //   //   //finally, connect to destination\n      //   //   mergerNode.connect(destination);\n      // }\n      // else {      //For normal live tracks\n      //   console.log('***NOT FILTERING: LIVE TRACK***')\n      //    //Pipe source *straight* to destination\n      //   audioSourceNode.connect(gainNode).connect(destination);\n      // }\n      //     //Attach to the audio element\n      //     audioEl.current.srcObject = destination.stream;\n      //END TODO\n      // how to do this without audiocontext:\n      audioEl.current.srcObject = new MediaStream([audioTrack]); // for debugging\n      // window.destination=destination; \n      // window.audioTrack=audioTrack;\n      // window.audioEl = audioEl;\n    }\n  }, [audioTrack, window.sessionState]);\n\n  function getVideoComponent() {\n    return videoTrack && /*#__PURE__*/React.createElement(\"video\", {\n      autoPlay: true,\n      muted: true,\n      playsInline: true,\n      ref: videoEl,\n      __self: this,\n      __source: {\n        fileName: _jsxFileName,\n        lineNumber: 230,\n        columnNumber: 26\n      }\n    });\n  }\n\n  function getAudioComponent() {\n    return !props.isLocalPerson && audioTrack && /*#__PURE__*/React.createElement(\"audio\", {\n      autoPlay: true,\n      playsInline: true,\n      ref: audioEl,\n      __self: this,\n      __source: {\n        fileName: _jsxFileName,\n        lineNumber: 238,\n        columnNumber: 21\n      }\n    }, \" \");\n  }\n\n  function getOverlayComponent() {\n    // Show overlay when video is unavailable. Audio may be unavailable too.\n    return videoTrack && videoUnavailableMessage && /*#__PURE__*/React.createElement(\"p\", {\n      className: \"overlay\",\n      __self: this,\n      __source: {\n        fileName: _jsxFileName,\n        lineNumber: 246,\n        columnNumber: 9\n      }\n    }, videoUnavailableMessage);\n  }\n\n  function getCornerMessageComponent() {\n    // Show corner message when only audio is unavailable.\n    return !props.disableCornerMessage && audioUnavailableMessage && !videoUnavailableMessage && /*#__PURE__*/React.createElement(\"p\", {\n      className: \"corner\",\n      __self: this,\n      __source: {\n        fileName: _jsxFileName,\n        lineNumber: 265,\n        columnNumber: 9\n      }\n    }, audioUnavailableMessage);\n  }\n\n  function getClassNames() {\n    let classNames = 'tile';\n    classNames += props.isLarge ? ' large' : ' small';\n    props.isLocalPerson && (classNames += ' local');\n    return classNames;\n  }\n\n  return (\n    /*#__PURE__*/\n    ///TODO change to block : none\n    React.createElement(\"div\", {\n      className: getClassNames(),\n      onClick: props.onClick,\n      style: {\n        display: videoTrack ? \"block\" : \"none\"\n      },\n      __self: this,\n      __source: {\n        fileName: _jsxFileName,\n        lineNumber: 279,\n        columnNumber: 5\n      }\n    }, /*#__PURE__*/React.createElement(\"div\", {\n      className: \"background\",\n      __self: this,\n      __source: {\n        fileName: _jsxFileName,\n        lineNumber: 280,\n        columnNumber: 7\n      }\n    }), getOverlayComponent(), getVideoComponent(), videoTrack && getCornerMessageComponent(), getAudioComponent())\n  );\n}","map":{"version":3,"sources":["/Users/arlosb/Documents/GitHub/new react app/test1/src/components/Tile/Tile.js"],"names":["React","useEffect","useMemo","useRef","useState","useForceUpdate","value","setValue","getTrackUnavailableMessage","kind","trackState","state","blocked","byPermissions","byDeviceMissing","off","byUser","byBandwidth","Tile","props","videoEl","audioEl","window","updateTile","videoTrack","videoTrackState","isLocalPerson","subscribed","track","audioTrack","audioTrackState","isAudioOnly","isFiltered","isScreenShare","videoUnavailableMessage","audioUnavailableMessage","current","srcObject","MediaStream","sessionState","getVideoComponent","getAudioComponent","getOverlayComponent","getCornerMessageComponent","disableCornerMessage","getClassNames","classNames","isLarge","onClick","display"],"mappings":";AAAA,OAAOA,KAAP,IAAgBC,SAAhB,EAA2BC,OAA3B,EAAoCC,MAApC,EAA4CC,QAA5C,QAA4D,OAA5D;AACA,OAAO,YAAP;;AACA,SAASC,cAAT,GAAyB;AACvB,QAAM,CAACC,KAAD,EAAQC,QAAR,IAAoBH,QAAQ,CAAC,CAAD,CAAlC,CADuB,CACgB;;AACvC,SAAO,MAAMG,QAAQ,CAACD,KAAK,IAAIA,KAAK,GAAG,CAAlB,CAArB,CAFuB,CAEoB;AAC5C;;AAED,SAASE,0BAAT,CAAoCC,IAApC,EAA0CC,UAA1C,EAAsD;AACpD,MAAI,CAACA,UAAL,EAAiB;;AACjB,UAAQA,UAAU,CAACC,KAAnB;AACE,SAAK,SAAL;AACE,UAAID,UAAU,CAACE,OAAX,CAAmBC,aAAvB,EAAsC;AACpC,eAAQ,GAAEJ,IAAK,oBAAf;AACD,OAFD,MAEO,IAAIC,UAAU,CAACE,OAAX,CAAmBE,eAAvB,EAAwC;AAC7C,eAAQ,GAAEL,IAAK,iBAAf;AACD;;AACD,aAAQ,GAAEA,IAAK,UAAf;;AACF,SAAK,KAAL;AACE,UAAIC,UAAU,CAACK,GAAX,CAAeC,MAAnB,EAA2B;AACzB,eAAQ,GAAEP,IAAK,QAAf;AACD,OAFD,MAEO,IAAIC,UAAU,CAACK,GAAX,CAAeE,WAAnB,EAAgC;AACrC,eAAQ,GAAER,IAAK,0BAAf;AACD;;AACD,aAAQ,GAAEA,IAAK,MAAf;;AACF,SAAK,UAAL;AACE,aAAQ,GAAEA,IAAK,iBAAf;;AACF,SAAK,SAAL;AACE,aAAQ,GAAEA,IAAK,aAAf;;AACF,SAAK,aAAL;AACE,aAAQ,GAAEA,IAAK,cAAf;;AACF,SAAK,UAAL;AACE,aAAO,IAAP;AAtBJ;AAwBD;AAED;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;;;AACA,eAAe,SAASS,IAAT,CAAcC,KAAd,EAAqB;AAClC,QAAMC,OAAO,GAAGjB,MAAM,CAAC,IAAD,CAAtB;AACA,QAAMkB,OAAO,GAAGlB,MAAM,CAAC,IAAD,CAAtB;;AACAmB,EAAAA,MAAM,CAACC,UAAP,GAAoB,MAAM;AACxBlB,IAAAA,cAAc;AACf,GAFD;;AAIA,QAAMmB,UAAU,GAAGtB,OAAO,CAAC,MAAM;AAC/B,WAAOiB,KAAK,CAACM,eAAN,IAAyBN,KAAK,CAACM,eAAN,CAAsBd,KAAtB,KAAgC,UAAzD,KAAwEQ,KAAK,CAACO,aAAN,IAAuBP,KAAK,CAACM,eAAN,CAAsBE,UAAtB,KAAqC,IAApI,IACHR,KAAK,CAACM,eAAN,CAAsBG,KADnB,GAEH,IAFJ;AAGD,GAJyB,EAIvB,CAACT,KAAK,CAACM,eAAP,CAJuB,CAA1B;AAMA,QAAMI,UAAU,GAAG3B,OAAO,CAAC,MAAM;AAE/B,QAAI,CAACiB,KAAK,CAACW,eAAP,IAA0B,CAACX,KAAK,CAACW,eAAN,CAAsBF,KAAjD,IAA0DT,KAAK,CAACW,eAAN,CAAsBnB,KAAtB,KAAgC,UAA1F,IAAwGQ,KAAK,CAACW,eAAN,CAAsBH,UAAtB,KAAqC,KAAjJ,EACI;AAAC,aAAO,IAAP;AAAa,KAHa,CAI/B;;;AACA,QAAIR,KAAK,CAACY,WAAV,EAAuB;AACrBZ,MAAAA,KAAK,CAACW,eAAN,CAAsBF,KAAtB,CAA4BI,UAA5B,GAAuC,IAAvC;AACD,KAFD,MAEO;AAACb,MAAAA,KAAK,CAACW,eAAN,CAAsBF,KAAtB,CAA4BI,UAA5B,GAAuC,KAAvC;AAA8C;;AACtD,QAAIb,KAAK,CAACc,aAAV,EAAyB;AACvBd,MAAAA,KAAK,CAACW,eAAN,CAAsBF,KAAtB,CAA4BK,aAA5B,GAA0C,IAA1C;AACD,KAFD,MAEO;AAACd,MAAAA,KAAK,CAACW,eAAN,CAAsBF,KAAtB,CAA4BK,aAA5B,GAA0C,KAA1C;AAAiD;;AACzD,WAAOd,KAAK,CAACW,eAAN,CAAsBF,KAA7B;AACD,GAZyB,EAYvB,CAACT,KAAK,CAACW,eAAP,CAZuB,CAA1B;AAcA,QAAMI,uBAAuB,GAAGhC,OAAO,CAAC,MAAM;AAC5C,WAAOM,0BAA0B,CAAC,OAAD,EAAUW,KAAK,CAACM,eAAhB,CAAjC;AACD,GAFsC,EAEpC,CAACN,KAAK,CAACM,eAAP,CAFoC,CAAvC;AAIA,QAAMU,uBAAuB,GAAGjC,OAAO,CAAC,MAAM;AAC5C,WAAOM,0BAA0B,CAAC,OAAD,EAAUW,KAAK,CAACW,eAAhB,CAAjC;AACD,GAFsC,EAEpC,CAACX,KAAK,CAACW,eAAP,CAFoC,CAAvC;AAIA;AACF;AACA;;AACE7B,EAAAA,SAAS,CAAC,MAAM;AACdmB,IAAAA,OAAO,CAACgB,OAAR,KACGhB,OAAO,CAACgB,OAAR,CAAgBC,SAAhB,GAA4B,IAAIC,WAAJ,CAAgB,CAACd,UAAD,CAAhB,CAD/B;AAED,GAHQ,EAGN,CAACA,UAAD,CAHM,CAAT;AAKA;AACF;AACA;;AACEvB,EAAAA,SAAS,CAAC,MAAM;AACd,QAAGoB,OAAO,CAACe,OAAX,EAAoB;AAIhB;AAGF;AACA;AAEA;AACA;AACA;AACA;AACA;AAEA;AACA;AACA;AACA;AAEA;AACA;AACA;AACA;AACA;AAQA;AACA;AACA;AACA;AACA;AACA;AACA;AAEA;AACA;AAEA;AACA;AACA;AAIA;AAEA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AAGA;AACA;AACA;AAEA;AACA;AACA;AAEA;AACA;AACA;AAEA;AACA;AAIA;AACA;AAEA;AACA;AAGA;AACA;AACA;AACA;AACA;AAEA;AACA;AACA;AACA;AACA;AAEA;AACA;AAEA;AACA;AACA;AACA;AAGA;AAIA;AAEA;AACA;AAEY;AAGX;AACCf,MAAAA,OAAO,CAACe,OAAR,CAAgBC,SAAhB,GAA4B,IAAIC,WAAJ,CAAgB,CAACT,UAAD,CAAhB,CAA5B,CAxHgB,CA8HlB;AACA;AACA;AACA;AAEC;AAEJ,GAtIQ,EAsIN,CAACA,UAAD,EAAYP,MAAM,CAACiB,YAAnB,CAtIM,CAAT;;AAwIA,WAASC,iBAAT,GAA6B;AAC3B,WAAOhB,UAAU,iBAAI;AAAO,MAAA,QAAQ,MAAf;AAAgB,MAAA,KAAK,MAArB;AAAsB,MAAA,WAAW,MAAjC;AAAkC,MAAA,GAAG,EAAEJ,OAAvC;AAAA;AAAA;AAAA;AAAA;AAAA;AAAA;AAAA,MAArB;AAGD;;AAED,WAASqB,iBAAT,GAA6B;AAC3B,WACE,CAACtB,KAAK,CAACO,aAAP,IACAG,UADA,iBACc;AAAO,MAAA,QAAQ,MAAf;AAAgB,MAAA,WAAW,MAA3B;AAA4B,MAAA,GAAG,EAAER,OAAjC;AAAA;AAAA;AAAA;AAAA;AAAA;AAAA;AAAA,WAFhB;AAID;;AAED,WAASqB,mBAAT,GAA+B;AAC7B;AACA,WAAOlB,UAAU,IACfU,uBAAuB,iBACrB;AAAG,MAAA,SAAS,EAAC,SAAb;AAAA;AAAA;AAAA;AAAA;AAAA;AAAA;AAAA,OACGA,uBADH,CAFJ;AAaD;;AAED,WAASS,yBAAT,GAAqC;AACnC;AACA,WACE,CAACxB,KAAK,CAACyB,oBAAP,IACAT,uBADA,IAEA,CAACD,uBAFD,iBAGE;AAAG,MAAA,SAAS,EAAC,QAAb;AAAA;AAAA;AAAA;AAAA;AAAA;AAAA;AAAA,OAAuBC,uBAAvB,CAJJ;AAOD;;AAED,WAASU,aAAT,GAAyB;AACvB,QAAIC,UAAU,GAAG,MAAjB;AACAA,IAAAA,UAAU,IAAI3B,KAAK,CAAC4B,OAAN,GAAgB,QAAhB,GAA2B,QAAzC;AACA5B,IAAAA,KAAK,CAACO,aAAN,KAAwBoB,UAAU,IAAI,QAAtC;AACA,WAAOA,UAAP;AACD;;AAED;AAAA;AACE;AACA;AAAK,MAAA,SAAS,EAAED,aAAa,EAA7B;AAAiC,MAAA,OAAO,EAAE1B,KAAK,CAAC6B,OAAhD;AAAyD,MAAA,KAAK,EAAE;AAACC,QAAAA,OAAO,EAAEzB,UAAU,GAAG,OAAH,GAAa;AAAjC,OAAhE;AAAA;AAAA;AAAA;AAAA;AAAA;AAAA;AAAA,oBACE;AAAK,MAAA,SAAS,EAAC,YAAf;AAAA;AAAA;AAAA;AAAA;AAAA;AAAA;AAAA,MADF,EAEGkB,mBAAmB,EAFtB,EAGGF,iBAAiB,EAHpB,EAIGhB,UAAU,IAAImB,yBAAyB,EAJ1C,EAKGF,iBAAiB,EALpB;AAFF;AAUD","sourcesContent":["import React, { useEffect, useMemo, useRef, useState } from 'react';\nimport './Tile.css';\nfunction useForceUpdate(){\n  const [value, setValue] = useState(0); // integer state\n  return () => setValue(value => value + 1); // update the state to force render\n}\n\nfunction getTrackUnavailableMessage(kind, trackState) {\n  if (!trackState) return;\n  switch (trackState.state) {\n    case 'blocked':\n      if (trackState.blocked.byPermissions) {\n        return `${kind} permission denied`;\n      } else if (trackState.blocked.byDeviceMissing) {\n        return `${kind} device missing`;\n      }\n      return `${kind} blocked`;\n    case 'off':\n      if (trackState.off.byUser) {\n        return `${kind} muted`;\n      } else if (trackState.off.byBandwidth) {\n        return `${kind} muted to save bandwidth`;\n      }\n      return `${kind} off`;\n    case 'sendable':\n      return `${kind} not subscribed`;\n    case 'loading':\n      return `${kind} loading...`;\n    case 'interrupted':\n      return `${kind} interrupted`;\n    case 'playable':\n      return null;\n  }\n}\n\n/**\n * Props\n * - videoTrackState: DailyTrackState?\n * - audioTrackState: DailyTrackState?\n * - isLocalPerson: boolean\n * - isAudioOnly: boolean\n * - isLarge: boolean\n * - disableCornerMessage: boolean\n * - onClick: Function\n * -isScreenShare: boolean\n */\nexport default function Tile(props) {\n  const videoEl = useRef(null);\n  const audioEl = useRef(null);\n  window.updateTile = () => {\n    useForceUpdate();\n  }\n\n  const videoTrack = useMemo(() => {\n    return props.videoTrackState && props.videoTrackState.state === 'playable' && (props.isLocalPerson || props.videoTrackState.subscribed === true)\n      ? props.videoTrackState.track\n      : null;\n  }, [props.videoTrackState]);\n\n  const audioTrack = useMemo(() => {\n\n    if (!props.audioTrackState || !props.audioTrackState.track || props.audioTrackState.state !== 'playable' || props.audioTrackState.subscribed === false) \n        {return null;}\n    // if(props.disableCornerMessage) {console.log('Is a screen share');}\n    if (props.isAudioOnly) {\n      props.audioTrackState.track.isFiltered=true;\n    } else {props.audioTrackState.track.isFiltered=false;}\n    if (props.isScreenShare) {\n      props.audioTrackState.track.isScreenShare=true;\n    } else {props.audioTrackState.track.isScreenShare=false;}\n    return props.audioTrackState.track\n  }, [props.audioTrackState]);\n\n  const videoUnavailableMessage = useMemo(() => {\n    return getTrackUnavailableMessage('video', props.videoTrackState);\n  }, [props.videoTrackState]);\n\n  const audioUnavailableMessage = useMemo(() => {\n    return getTrackUnavailableMessage('audio', props.audioTrackState);\n  }, [props.audioTrackState]);\n\n  /**\n   * When video track changes, update video srcObject\n   */\n  useEffect(() => {\n    videoEl.current &&\n      (videoEl.current.srcObject = new MediaStream([videoTrack]));\n  }, [videoTrack]);\n\n  /**\n   * When audio track changes, update audio srcObject\n   */\n  useEffect(() => {\n    if(audioEl.current) {\n\n\n\n        // TODO: PUT THIS BACK\n\n\n      // //create audio stream\n      // window.stream= window.stream || new MediaStream([audioTrack]);\n\n      // //workaround for bug in Chrome, see: https://bit.ly/3ryn1fW\n      //       window.mutedAudio = window.mutedAudio || new Audio(); \n      //       window.mutedAudio.muted = true;\n      //       if(!window.mutedAudio.srcObject) {window.mutedAudio.srcObject = window.stream;}\n      //       window.mutedAudio.paused && window.mutedAudio.play(); \n\n      // //create Audio Context and destination\n      // window.audioCtx = new (window.AudioContext || window.webkitAudioContext)();\n      // let audioSourceNode = window.audioCtx.createMediaStreamSource(window.stream);\n      // let destination = window.audioCtx.createMediaStreamDestination();\n\n      // //gain Node\n      // let gainNode = window.audioCtx.createGain();\n      // //panner Node\n      // var panNode = window.audioCtx.createStereoPanner();\n      // //splitter\n      \n\n\n\n\n\n      \n      // if(audioTrack.isFiltered) {\n      //   console.log('**FILTERING LIVE TRACK**')\n      //         //adjust nodes\n      //         gainNode.gain.value=1;\n      //         panNode.pan.value=1;      \n      //         //Pipe source through nodes to destination\n      //       audioSourceNode.connect(gainNode).connect(panNode).connect(destination);\n        \n      // } \n      // else if(audioTrack.isScreenShare) {\n\n      //   //for everyone, just piping the received audio (which was the left channel of the original video) straight through\n      //   console.log('***GETTING SCREENSHARE AUDIO')\n      //   audioSourceNode.connect(destination);\n\n\n\n      //   ///OLD CODE FOR IF IT RECEIVED STEREO AUDIO:\n        \n      //   // const splitterNode = new ChannelSplitterNode(audioCtx, { numberOfOutputs: 2 });\n      //   // const splitterNodeLL = new ChannelSplitterNode(audioCtx, { numberOfOutputs: 2 });\n      //   // const mergerNode = new ChannelMergerNode(audioCtx, { numberOfInputs: 2 });\n      //   // const mergerNodeR = new ChannelMergerNode(audioCtx, { numberOfInputs: 2 });\n      //   // const volumeNodeL = new GainNode(audioCtx);\n      //   // const volumeNodeR = new GainNode(audioCtx);\n      //   // if(window.myRole.includes('Actor')) {   //For actors, mix left channel into both sides and keep right channel\n      //   //   console.log('**FILTERING: SCREENSHARE AUDIO FOR ACTOR**')\n\n\n      //   //   // //split audio source into 2 channels: 0 (left), and 1(right)\n      //   //   // audioSourceNode.connect(splitterNode)  \n      //   //   // splitterNode.connect(splitterNodeLL,0); //split left channel again\n\n      //   //   // //mix the left and right into the new right channel\n      //   //   // splitterNodeLL.connect(mergerNodeR, 0, 1); // Merge right of the left channel into right side\n      //   //   // splitterNode.connect(mergerNodeR, 0, 1); // Merge right channel into right side\n\n      //   //   // //merge far left and new right\n      //   //   // splitterNodeLL.connect(mergerNode, 0, 0);\n      //   //   // mergerNodeR.connect(mergerNode, 0, 1);\n\n      //   //   audioSourceNode.connect(mergerNode,0,0);\n      //   //   audioSourceNode.connect(mergerNode,0,1);\n\n          \n\n      //   // } else {        //For everyone else , mix left channel into both sides and mute right channel\n      //   //   console.log('**FILTERING: SCREENSHARE AUDIO FOR OBSERVER**')\n\n      //   //   //split audio source into 2 channels: 0 (left), and 1(right)\n      //   //   audioSourceNode.connect(splitterNode)\n\n\n      //   //   //adjust channels separately\n      //   //   splitterNode.connect(volumeNodeL, 0); // connect Left channel to its volume node\n      //   //   splitterNode.connect(volumeNodeR, 1); // connect Right channel to its volume node\n      //   //   volumeNodeL.gain.value = 1; //set Left volume\n      //   //   volumeNodeR.gain.value = 1; //set Right volume\n\n      //   //   //merge the channels\n      //   //   volumeNodeL.connect(mergerNode, 0, 0); // Merge left channel\n      //   //   volumeNodeR.connect(mergerNode, 0, 1); // Merge right channel\n      //   //   // volumeNodeR.connect(mergerNode, 0, 0);\n      //   // }\n\n      //   //   //finally, connect to destination\n      //   //   mergerNode.connect(destination);\n\n      // }\n      // else {      //For normal live tracks\n      //   console.log('***NOT FILTERING: LIVE TRACK***')\n      //    //Pipe source *straight* to destination\n\n\n      //   audioSourceNode.connect(gainNode).connect(destination);\n\n     \n\n      // }\n\n      //     //Attach to the audio element\n      //     audioEl.current.srcObject = destination.stream;\n\n                  //END TODO\n\n\n       // how to do this without audiocontext:\n        audioEl.current.srcObject = new MediaStream([audioTrack]);\n\n     \n\n  \n\n      // for debugging\n      // window.destination=destination; \n      // window.audioTrack=audioTrack;\n      // window.audioEl = audioEl;\n\n      }\n      \n  }, [audioTrack,window.sessionState]);\n\n  function getVideoComponent() {\n    return videoTrack && <video autoPlay muted playsInline ref={videoEl} />;\n\n    \n  }\n\n  function getAudioComponent() {\n    return (\n      !props.isLocalPerson &&\n      audioTrack && <audio autoPlay playsInline ref={audioEl} > </audio>\n    );\n  }\n\n  function getOverlayComponent() {\n    // Show overlay when video is unavailable. Audio may be unavailable too.\n    return videoTrack && (\n      videoUnavailableMessage && (\n        <p className=\"overlay\">\n          {videoUnavailableMessage}\n          {/* {audioUnavailableMessage && (\n            <>\n              <br />\n              {audioUnavailableMessage}\n            </>\n          )} */}\n        </p>\n      )\n    );\n  }\n\n  function getCornerMessageComponent() {\n    // Show corner message when only audio is unavailable.\n    return (\n      !props.disableCornerMessage &&\n      audioUnavailableMessage &&\n      !videoUnavailableMessage && (\n        <p className=\"corner\">{audioUnavailableMessage}</p>\n      )\n    );\n  }\n\n  function getClassNames() {\n    let classNames = 'tile';\n    classNames += props.isLarge ? ' large' : ' small';\n    props.isLocalPerson && (classNames += ' local');\n    return classNames;\n  }\n\n  return (\n    ///TODO change to block : none\n    <div className={getClassNames()} onClick={props.onClick} style={{display: videoTrack ? \"block\" : \"none\"}}  >  \n      <div className=\"background\"/> \n      {getOverlayComponent()}\n      {getVideoComponent()}\n      {videoTrack && getCornerMessageComponent()}\n      {getAudioComponent()}\n    </div>\n  );\n}\n"]},"metadata":{},"sourceType":"module"}